import os
import hashlib
import subprocess
import psutil
import time
import joblib
from flask import Flask, request, render_template, jsonify

# Initialize Flask app
app = Flask(__name__)
UPLOAD_FOLDER = "uploads"
RESULTS_FOLDER = "results"
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(RESULTS_FOLDER, exist_ok=True)

# Load pre-trained machine learning model
MODEL_PATH = "trained_model.pkl"  #use yours
model = joblib.load(MODEL_PATH)

# Function to calculate file hashes
def calculate_hash(file_path):
    hashes = {}
    with open(file_path, "rb") as f:
        file_content = f.read()
        hashes["md5"] = hashlib.md5(file_content).hexdigest()
        hashes["sha1"] = hashlib.sha1(file_content).hexdigest()
        hashes["sha256"] = hashlib.sha256(file_content).hexdigest()
    return hashes

# Extract features for ML model
def extract_features(file_path):
    file_size = os.path.getsize(file_path)
    hashes = calculate_hash(file_path)
    return [
        len(hashes["sha256"]),
        file_size,
    ]

# Predict using ML model
def predict_with_ml(file_path):
    features = extract_features(file_path)
    prediction = model.predict([features])[0]
    confidence = model.predict_proba([features]).max()
    return {"label": prediction, "confidence": confidence}

# Monitor processes during dynamic analysis
def monitor_process(proc):
    process_data = {
        "pid": proc.pid,
        "name": proc.name(),
        "cmdline": proc.cmdline(),
        "cpu_usage": proc.cpu_percent(interval=1.0),
        "memory_info": proc.memory_info()._asdict(),
    }
    return process_data

# Dynamic analysis function
def dynamic_analysis(file_path):
    logs = []
    try:
        proc = subprocess.Popen([file_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        parent = psutil.Process(proc.pid)
        time.sleep(5)  
        children = parent.children(recursive=True)
        for child in children:
            logs.append(monitor_process(child))
        proc.terminate()
    except Exception as e:
        logs.append({"error": str(e)})
    return logs

# Main analysis function
def analyze_file(file_path):
    results = {"static": {}, "dynamic": {}, "ml": {}}
    
    # Static analysis
    results["static"] = calculate_hash(file_path)
    
    # Dynamic analysis
    results["dynamic"] = dynamic_analysis(file_path)
    
    # Behavior analysis (ML)
    results["ml"] = predict_with_ml(file_path)
    
    return results

# Flask routes
@app.route("/")
def index():
    return render_template("index.html")

@app.route("/analyze", methods=["POST"])
def analyze():
    if "file" not in request.files:
        return jsonify({"error": "No file uploaded"}), 400
    
    uploaded_file = request.files["file"]
    if uploaded_file.filename == "":
        return jsonify({"error": "No file selected"}), 400
    
    file_path = os.path.join(UPLOAD_FOLDER, uploaded_file.filename)
    uploaded_file.save(file_path)
    
    # Perform analysis
    results = analyze_file(file_path)
    
    # Save results to log
    results_file = os.path.join(RESULTS_FOLDER, f"{uploaded_file.filename}.json")
    with open(results_file, "w") as f:
        f.write(str(results))
    
    return jsonify(results)

@app.route("/results/<filename>")
def get_results(filename):
    results_file = os.path.join(RESULTS_FOLDER, filename)
    if os.path.exists(results_file):
        with open(results_file, "r") as f:
            return f.read()
    return jsonify({"error": "Results not found"}), 404

# Run the app
if __name__ == "__main__":
    app.run(debug=True)
